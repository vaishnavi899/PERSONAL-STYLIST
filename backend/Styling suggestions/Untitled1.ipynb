{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fcade7b-1180-49a9-8a99-cf41efcef0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import GlobalMaxPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from numpy.linalg import norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "072cf3a1-e44e-448e-8d48-862d6121cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "model = Sequential([base_model, GlobalMaxPool2D()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bd36399-d06d-42ae-a2e7-f32fdd401306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define clothing categories\n",
    "categories = [\"bottomwear\", \"topwear\", \"shoes\", \"accessories\"]\n",
    "\n",
    "# Function to extract features from images\n",
    "def extract_features_from_images(image_path, model):\n",
    "    try:\n",
    "        img = image.load_img(image_path, target_size=(224, 224))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_expand_dim = np.expand_dims(img_array, axis=0)\n",
    "        img_preprocess = preprocess_input(img_expand_dim)\n",
    "        result = model.predict(img_preprocess, verbose=0).flatten()\n",
    "        norm_result = result / norm(result)\n",
    "        return norm_result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        return np.zeros(2048)  # Ensure consistent feature vector size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c91166ed-c86a-49ad-aee8-cd853106f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(base_path, model):\n",
    "    labels = []\n",
    "    features = []\n",
    "    filenames = []\n",
    "\n",
    "    for category in categories:\n",
    "        folder_path = os.path.join(base_path, category)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Warning: Folder {folder_path} does not exist.\")\n",
    "            continue\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            try:\n",
    "                feature = extract_features_from_images(file_path, model)\n",
    "                if feature is not None:\n",
    "                    features.append(feature)\n",
    "                    labels.append(category)\n",
    "                    filenames.append(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    return features, labels, filenames\n",
    "\n",
    "# Specify dataset path\n",
    "base_path = \"C:/Users/asus/Downloads/Styling suggestions/\"\n",
    "\n",
    "# Extract features, labels, and filenames\n",
    "features, labels, filenames = prepare_dataset(base_path, model)\n",
    "\n",
    "# Save extracted data\n",
    "pkl.dump(features, open(\"Images_features.pkl\", \"wb\"))\n",
    "pkl.dump(labels, open(\"labels.pkl\", \"wb\"))\n",
    "pkl.dump(filenames, open(\"filenames.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65c2a07b-c5c1-4790-b04a-a6761ea03277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(features, labels):\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)\n",
    "    svm_classifier = SVC(probability=True, kernel='linear')\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    print(\"Model training completed.\")\n",
    "    return svm_classifier, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ad05921-71f1-4af0-9665-fec9dba67193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed.\n"
     ]
    }
   ],
   "source": [
    "svm_classifier, label_encoder = train_classifier(features, labels)\n",
    "\n",
    "# Save the trained model and encoder\n",
    "pkl.dump(svm_classifier, open(\"category_classifier.pkl\", \"wb\"))\n",
    "pkl.dump(label_encoder, open(\"label_encoder.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d6c9081-d950-4d3c-acad-ce760fbe591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained classifier and label encoder\n",
    "svm_classifier = pkl.load(open(\"category_classifier.pkl\", \"rb\"))\n",
    "label_encoder = pkl.load(open(\"label_encoder.pkl\", \"rb\"))\n",
    "\n",
    "# Load extracted dataset features and filenames\n",
    "database_features = pkl.load(open(\"Images_features.pkl\", \"rb\"))\n",
    "database_filenames = pkl.load(open(\"filenames.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e54a99af-8100-497d-a35d-68946f1f0f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image uploads/OIP.jpg: [Errno 2] No such file or directory: 'uploads/OIP.jpg'\n",
      "Classified as: accessories\n",
      "Category: accessories\n",
      "Recommendations:\n",
      "bottomwear: ['C:/Users/asus/Downloads/Styling suggestions/bottomwear\\\\c6bc821e-631a-4221-9d92-7c7685edebd0.jpg', 'C:/Users/asus/Downloads/Styling suggestions/bottomwear\\\\56fda6ba-1ee9-4f97-a0fd-55f01f1e2512.jpg', 'C:/Users/asus/Downloads/Styling suggestions/bottomwear\\\\cbf45350-1a65-4cec-abad-0f64a4a459eb.jpg']\n",
      "shoes: ['C:/Users/asus/Downloads/Styling suggestions/shoes\\\\f5ed50b6-79b3-4d9d-84a9-8010f5e1c581.jpg', 'C:/Users/asus/Downloads/Styling suggestions/shoes\\\\5d147b66-5238-4ed0-9c6f-c68286fea4ad.jpg', 'C:/Users/asus/Downloads/Styling suggestions/shoes\\\\da73c56d-32ac-4d66-bdb2-82c50adcdde7.jpg']\n",
      "topwear: ['C:/Users/asus/Downloads/Styling suggestions/topwear\\\\ffa2be27-0798-488d-b9de-254de2226667.jpg', 'C:/Users/asus/Downloads/Styling suggestions/topwear\\\\e917e5f9-2394-4e18-a69d-bacaa9a6a3a1.jpg', 'C:/Users/asus/Downloads/Styling suggestions/topwear\\\\d9afe9d4-8bb3-4449-9e4b-85fcf030ba1b.jpg']\n"
     ]
    }
   ],
   "source": [
    "def classify_and_recommend(image_path, model, classifier, encoder, db_features, db_filenames):\n",
    "    features = extract_features_from_images(image_path, model)\n",
    "    category_idx = classifier.predict([features])[0]\n",
    "    category = encoder.inverse_transform([category_idx])[0]\n",
    "    print(f\"Classified as: {category}\")\n",
    "\n",
    "    other_categories = [cat for cat in encoder.classes_ if cat != category]\n",
    "    recommendations = {}\n",
    "\n",
    "    for other_category in other_categories:\n",
    "        indices = [i for i, fname in enumerate(db_filenames) if other_category in fname]\n",
    "        if not indices:\n",
    "            print(f\"No images found for category: {other_category}\")\n",
    "            continue\n",
    "        random_indices = random.sample(indices, min(3, len(indices)))\n",
    "        recommendations[other_category] = [db_filenames[i] for i in random_indices]\n",
    "\n",
    "    return category, recommendations\n",
    "\n",
    "# Upload and classify an image\n",
    "uploaded_image = r\"uploads/OIP.jpg\"\n",
    "category, recommendations = classify_and_recommend(\n",
    "    uploaded_image, model, svm_classifier, label_encoder, database_features, database_filenames\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(f\"Category: {category}\")\n",
    "print(\"Recommendations:\")\n",
    "for rec_category, rec_files in recommendations.items():\n",
    "    print(f\"{rec_category}: {rec_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5055af9c-d8dd-4451-b849-478f91849746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c753a9e-fe12-4527-b9ba-555af373da0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116036a-9eba-44a6-97a7-bf063821933a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36427c7-5684-4932-b511-a25a93c60ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ba657-3a84-4cd3-abbe-0afa8b1ab2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf7588-b3d4-4d8c-8856-91d194c2c7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc629820-be44-4a34-9821-ca37b9a5b1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
